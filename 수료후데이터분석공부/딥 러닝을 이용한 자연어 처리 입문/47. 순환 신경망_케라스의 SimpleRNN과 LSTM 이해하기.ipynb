{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 임의의 입력 생성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import SimpleRNN, LSTM, Bidirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]\n",
    "print(np.shape(train_X))\n",
    "# 단어 벡터의 차원은 5, 문장의 길이는 4\n",
    "# 4번의 시점(timesteps) 존재, 각 시점마다 5차원의 단어 벡터가 입력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "그런데 RNN은 2D 텐서가 아니라 3D 텐서를 입력을 받는다!\n",
    "\n",
    "배치 크기 1을 추가해 2D 텐서를 3D 텐서로 변경"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 4, 5)\n"
     ]
    }
   ],
   "source": [
    "train_X = [[[0.1, 4.2, 1.5, 1.1, 2.8], [1.0, 3.1, 2.5, 0.7, 1.1], [0.3, 2.1, 1.5, 2.1, 0.1], [2.2, 1.4, 0.5, 0.9, 1.1]]]\n",
    "train_X = np.array(train_X, dtype=np.float32)\n",
    "print(train_X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(batch_size, timesteps, input_dim)에 해당되는 (1,4,5)의 크기를 가지는 3D 텐서 생성"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. SimpleRNN 이해하기\n",
    "*은닉 상태의 크기를 3으로 지정*\n",
    "\n",
    "*default값 -> return_sequences=False, return_state=False*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.96619076 -0.98537946  0.46676216]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3)\n",
    "hidden_state = rnn(train_X)\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "마지막 시점의 은닉 상태(return_sequences=False 이기 때문) -> (1,3) 크기의 텐서\n",
    "\n",
    "\n",
    "\n",
    "*return_sequences=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.2627316   0.8183764  -0.97382116]\n",
      "  [-0.832201    0.03026401 -0.8842984 ]\n",
      "  [-0.895025   -0.5673464  -0.9937178 ]\n",
      "  [-0.23107468  0.7446457  -0.9913012 ]]], shape: (1, 4, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True)\n",
    "hidden_states = rnn(train_X)\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모든 시점의 은닉 상태 -> (1, 4, 3) 크기의 텐서\n",
    "\n",
    "앞서 입력 데이터는 (1, 4, 5)의 크기를 가지는 3D 텐서였고, 그 중 4가 시점(timesteps)에 해당하는 값이므로 모든 시점에 대해서 은닉 상태의 값을 출력하여 (1, 4, 3) 크기의 텐서를 출력\n",
    "\n",
    "**return_state가 True일 경우에는 return_sequences의 True/False 여부와 상관없이 마지막 시점의 은닉 상태를 출력**\n",
    "\n",
    "*return_sequences=True, return_state=True* => 두 개의 출력 리턴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.2627316   0.8183764  -0.97382116]\n",
      "  [-0.832201    0.03026401 -0.8842984 ]\n",
      "  [-0.895025   -0.5673464  -0.9937178 ]\n",
      "  [-0.23107468  0.7446457  -0.9913012 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[-0.97204787 -0.2426457  -0.41747177]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=True, return_state=True)\n",
    "hidden_sates, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 첫번째 출력은 return_sequences=True로 인한 출력으로 모든 시점의 은닉 상태\n",
    "* 두번째 출력은 return_state=True로 인한 출력으로 마지막 시점의 은닉 상태\n",
    "\n",
    "*return_sequences=False, return_state=True* => 두 개 모두 마지막 시점의 은닉 상태 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[-0.5899451  0.560449  -0.9985396]], shape: (1, 3)\n",
      "last hidden state : [[-0.5899451  0.560449  -0.9985396]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "rnn = SimpleRNN(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state = rnn(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. LSTM 이해하기\n",
    "*return_sequences=False, return_state=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden state : [[ 0.04883935 -0.1619133   0.25500563]], shape: (1, 3)\n",
      "last hidden state : [[ 0.04883935 -0.1619133   0.25500563]], shape: (1, 3)\n",
      "last cell state : [[ 0.11907516 -1.0246807   0.4353762 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=False, return_state=True)\n",
    "hidden_state, last_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden state : {}, shape: {}'.format(hidden_state, hidden_state.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_state, last_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 첫번째 결과는 return_sequences=False 로 인해 마지막 시점의 은닉 상태\n",
    "* return_state=True로 마지막 시점의 은닉 상태와 셀 상태 반환\n",
    "* **return_state=True를 사용하면 셀 상태 반환**\n",
    "\n",
    "*return_sequences=True, return_state=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[ 0.2627316   0.8183764  -0.97382116]\n",
      "  [-0.832201    0.03026401 -0.8842984 ]\n",
      "  [-0.895025   -0.5673464  -0.9937178 ]\n",
      "  [-0.23107468  0.7446457  -0.9913012 ]]], shape: (1, 4, 3)\n",
      "last hidden state : [[ 0.41554204 -0.00167021 -0.6411589 ]], shape: (1, 3)\n",
      "last cell state : [[ 0.5781597  -0.00297771 -1.1284821 ]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "lstm = LSTM(3, return_sequences=True, return_state=True)\n",
    "hidden_state, last_hidden_state, last_cell_state = lstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('last hidden state : {}, shape: {}'.format(last_hidden_state, last_hidden_state.shape))\n",
    "print('last cell state : {}, shape: {}'.format(last_cell_state, last_cell_state.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* return_state=True이므로 두번째 출력값이 마지막 은닉 상태, 세번째는 마지막 셀 상태 반환\n",
    "* return_sequences=True로 첫번째 출력값은 모든 시점의 은닉 상태 출력"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Bidirectional(LSTM) 이해하기\n",
    "*출력되는 은닉 상태의 값 고정*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "k_init = tf.keras.initializers.Constant(value=0.1)\n",
    "b_init = tf.keras.initializers.Constant(value=0)\n",
    "r_init = tf.keras.initializers.Constant(value=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*return_sequences=False, return_state=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[0.6303138 0.6303138 0.6303138 0.7038734 0.7038734 0.7038734]], shape: (1, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=False, return_state=True, kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* return_state=True로 셀 상태 반환 => 정방향 LSTM의 은닉 상태와 셀 상태, 역방향 LSTM의 은닉 상태와 셀 상태\n",
    "* 첫번째 출력값이 (1,6)이다. -> return_sequences=False이면 정방향 LSTM의 마지막 시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉 상태가 연결된 채 반환되기 때문\n",
    "* 반환된 은닉 상태의 값인 forward_h와 backward_h는 각각 정방향 LSTM의 마지막 시점의 은닉 상태와 역방향 LSTM의 첫번째 시점의 은닉 상태값으로 이 두 값을 연결한 값이 hidden_states에 출력되는 값이다.\n",
    "\n",
    "*return_sequences=True, return_state=True*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hidden states : [[[0.35906473 0.35906473 0.35906473 0.7038734  0.7038734  0.7038734 ]\n",
      "  [0.55111325 0.55111325 0.55111325 0.58863586 0.58863586 0.58863586]\n",
      "  [0.59115744 0.59115744 0.59115744 0.3951699  0.3951699  0.3951699 ]\n",
      "  [0.6303138  0.6303138  0.6303138  0.21942244 0.21942244 0.21942244]]], shape: (1, 4, 6)\n",
      "forward state : [[0.6303138 0.6303138 0.6303138]], shape: (1, 3)\n",
      "backward state : [[0.7038734 0.7038734 0.7038734]], shape: (1, 3)\n"
     ]
    }
   ],
   "source": [
    "bilstm = Bidirectional(LSTM(3, return_sequences=True, return_state=True, kernel_initializer=k_init, bias_initializer=b_init, recurrent_initializer=r_init))\n",
    "hidden_states, forward_h, forward_c, backward_h, backward_c = bilstm(train_X)\n",
    "\n",
    "print('hidden states : {}, shape: {}'.format(hidden_states, hidden_states.shape))\n",
    "print('forward state : {}, shape: {}'.format(forward_h, forward_h.shape))\n",
    "print('backward state : {}, shape: {}'.format(backward_h, backward_h.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* hidden states의 출력값에서는 이제 모든 시점의 은닉 상태가 출력\n",
    "* 역방향 LSTM의 첫번째 시점의 은닉 상태는 더 이상 정방향 LSTM의 마지막 시점의 은닉 상태와 연결되는 것이 아니라 정방향 LSTM의 첫번째 시점의 은닉 상태와 연결"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
