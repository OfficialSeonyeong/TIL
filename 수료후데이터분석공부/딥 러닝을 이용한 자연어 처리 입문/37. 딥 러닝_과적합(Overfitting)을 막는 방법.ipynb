{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "모델이 과적합되면 훈련 데이터에 대한 정확도는 높을지라도, 새로운 데이터. 즉, 검증 데이터나 테스트 데이터에 대해서는 제대로 동작하지 않는다.\n",
    "\n",
    "**인공 신경망의 과적합을 막는 방법**\n",
    "\n",
    "## 1. 데이터의 양을 늘리기\n",
    "* 모델은 데이터의 양이 적을 경우, 해당 데이터의 특정 패턴이나 노이즈까지 쉽게 암기하기 되므로 과적합 현상이 발생할 확률이 늘어난다.\n",
    "* 데이터의 양을 늘릴 수록 모델은 데이터의 일반적인 패턴을 학습하여 과적합을 방지할 수 있다.\n",
    "* 데이터의 양이 적을 경우에는 의도적으로 기존의 데이터를 조금씩 변형하고 추가하여 데이터의 양을 늘리기도 하는데 이를 데이터 증식 또는 증강(Data Augmentation)이라고 한다.\n",
    "\n",
    "## 2. 모델의 복잡도 줄이기\n",
    "* 인공 신경망의 복잡도는 은닉층(hidden layer)의 수나 매개변수의 수 등으로 결정\n",
    "* 과적합 현상이 포착되었을 때 인공 신경망의 복잡도를 줄인다.\n",
    "\n",
    "## 3. 가중치 규제(Regularization) 적용하기\n",
    "* 복잡한 모델을 간단하게 하는 방법 => 가중치 규제\n",
    "    * L1 규제 : 가중치 w들의 절대값 합계를 비용 함수에 추가, L1 노름이라고도 한다.\n",
    "    * L2 규제 : 모든 가중치 w들의 제곱합을 비용 함수에 추가, L2 노름이라고도 한다.\n",
    "* λ 는 규제의 강도를 정하는 하이퍼파라미터, λ가 크다면 모델이 훈련 데이터에 대해서 적합한 매개 변수를 찾는 것보다 규제를 위해 추가된 항들을 작게 유지하는 것을 우선한다는 의미\n",
    "* 두 식 모두 비용 함수를 최소화하기 위해서는 가중치 w들의 값이 작아져야 한다는 특징이 있다.\n",
    "*  L1 규제를 사용하면 비용 함수가 최소가 되게 하는 가중치와 편향을 찾는 동시에 가중치들의 절대값의 합도 최소가 되어야 한다. => 가중치 w의 값들은 0 또는 0에 가까이 작아져야 하므로 어떤 특성들은 모델을 만들 때 거의 사용되지 않게 된다.\n",
    "* L2 규제는 L1 규제와는 달리 가중치들의 제곱을 최소화하므로 w의 값이 완전히 0이 되기보다는 0에 가까워지기는 경향을 띈다.\n",
    "* L1 규제는 어떤 특성들이 모델에 영향을 주고 있는지를 정확히 판단하고자 할 때 유용하다. 만약, 이런 판단이 필요없다면 경험적으로는 L2 규제가 더 잘 동작하므로 L2 규제를 더 권장\n",
    "\n",
    "## 4. 드롭아웃(Dropout)\n",
    "* 학습 과정에서 신경망의 일부를 사용하지 않는 방법\n",
    "* 드롭아웃은 신경망 학습 시에만 사용하고, 예측 시에는 사용하지 않는 것이 일반적\n",
    "* 학습 시에 인공 신경망이 특정 뉴런 또는 특정 조합에 너무 의존적이게 되는 것을 방지해주고, 매번 랜덤 선택으로 뉴런들을 사용하지 않으므로 서로 다른 신경망들을 앙상블하여 사용하는 것 같은 효과를 내어 과적합을 방지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 드롭 아웃 예시\n",
    "model = Sequential()\n",
    "model.add(Dense(256, input_shape=(max_words,), activation='relu'))\n",
    "model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.5)) # 드롭아웃 추가. 비율은 50%\n",
    "model.add(Dense(num_classes, activation='softmax'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
