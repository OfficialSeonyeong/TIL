{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 기존 N-gram 언어 모델의 한계\n",
    "* 문장에 확률을 할당하는 모델\n",
    "* 주어진 문맥으로부터 아직 모르는 단어를 예측하는 것을 언어 모델링이라고 한다.\n",
    "* n-gram 언어 모델은 언어 모델링에 바로 앞의 n-1개의 단어만 참고\n",
    "* 하지만 충분한 데이터를 관측하지 못하면 언어를 정확히 모델링하지 못하는 **희소 문제(sparsity problem)** 발생\n",
    "\n",
    "\n",
    "## 2. 단어의 의미적 유사성\n",
    "* 희소 문제는 기계가 단어 간 유사도를 알 수 있다면 해결할 수 있다.\n",
    "* => 단어 간 유사도를 반영한 벡터를 만드는 **워드 임베딩(word embedding)**\n",
    "\n",
    "\n",
    "## 3. 피드 포워드 신경망 언어 모델(NNLM)\n",
    "* 훈련 코퍼스 준비 -> 모든 단어를 숫자로 인코딩/원핫 인코딩 => NNLM의 입력이면서 예측을 위한 레이블\n",
    "* NNLM은 정해진 n개의 단어만 참고\n",
    "* 원핫 벡터를 입력 받은 NNLM은 다음층인 투사층(projection layer)을 지난다.\n",
    "* 보통 은닉층이라고 부르지만 여기서는 투사층으로 일반 은닉층과 다르게 가중치 행렬과의 연산은 이루어지지만 활성화 함수가 존재하지 않는다.\n",
    "* 투사층의 크기를 M으로 설정하면, 각 입력 단어들은 투사층에서 V X M 크기의 가중치 행렬과 곱해진다.\n",
    "* 원핫 벡터와 가중치 W 행렬의 곱은 W행렬의 i번째 행을 그대로 읽어오는 것과 동일해 lookup table이라고 부른다.\n",
    "* 룩업 테이블 작업을 거치면 V의 차원을 가지는 원핫 벡터는 이보다 더 차원이 작은 M차원의 단어 벡터로 맵핑된다.이 벡터들은 초기에는 랜덤한 값을 가지지만 학습 과정에서 값이 계속 변경되는데 이 단어 벡터를 **임베딩 벡터**라고 한다.\n",
    "* 각 단어가 테이블 룩업을 통해 임베딩 벡터로 변경되고 투사층에서 모든 임베딩 벡터들의 값은 연결(concatenation)이 된다.\n",
    "* 투사층은 활성화 함수가 존재하지 않는 선형층(linear layer)이고 그 다음부터는 다시 은닉층 사용\n",
    "* 투사층의 결과는 h의 크기를 가지는 은닉층을 지난다.(= 은닉층의 입력은 가중치 곱해진 후 편향이 더해져 활성화 함수의 입력이 된다.)\n",
    "* 은닉층의 출력은 이제 V의 크기를 가지는 출력층으로 향한다. 이 과정에서 다시 또 다른 가중치와 곱해지고 편향이 더해지면 입력이었던 원핫 벡터들과 동일하게 V차원의 벡터를 얻는다.\n",
    "* 출력층에서 활성화 함수를 지나면서 해당 활성화 함수에 알맞은 값으로 바뀌고 이 값은 NNLM의 예측값(y^)이 된다.\n",
    "* 실제값 y 벡터와 가까워지게 하기 위해서 손실 함수 사용\n",
    "* 역전파가 이루어지면서 가중치 행렬 학습, 임베딩 벡터값 학습\n",
    "\n",
    "## 4. NNLM의 이점과 한계\n",
    "### 1) 기존 모델에서의 개선점\n",
    "NNLM은 밀집 벡터(dense vector)를 사용해 단어의 유사도 표현 -> n-gram 언어 모델보다 저장 공간의 이점\n",
    "\n",
    "### 2) 고정된 길이의 입력(Fixed-length input)\n",
    "NNLM은 n-gram 언어 모델과 마찬가지로 다음 단어를 예측하기 위해 모든 이전 단어를 참고하는 것이 아니라, 정해진 n개의 단어만을 참고 -> 버려지는 단어들이 가진 문맥 정보는 참고할 수 없음\n",
    "\n",
    "훈련 코퍼스에 있는 각 문장의 길이는 전부 다를 수 있으므로, 이를 개선하기 위해서는 모델이 매번 다른 길이의 입력 시퀀스에 대해서 도 처리할 수 있는 능력이 필요"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
