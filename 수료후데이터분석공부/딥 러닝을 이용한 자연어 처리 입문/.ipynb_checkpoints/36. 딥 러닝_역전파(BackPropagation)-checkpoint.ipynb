{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*어떻게 역전파 과정에서 경사 하강법을 사용하여 가중치를 업데이트하는지 직접 계산을 통해 이해하기*\n",
    "\n",
    "가정: 두 개의 입력과 두 개의 은닉층 뉴런, 두 개의 출력층 뉴런 사용, 활성화 함수는 시그모이드 함수 사용, 편향 b는 고려X\n",
    "\n",
    "## 순전파(Forward Propagation)\n",
    "1. 각 입력은 은닉층 방향으로 향하면서 각 입력에 해당되는 가중치와 곱해지고, 결과적으로 가중합으로 계산되어 은닉층 뉴런의 시그모이드 함수의 입력값이 된다.\n",
    "\n",
    "```z1 = W1x1 + W2x2``` \n",
    "```z2 = W3Xx1 + W4Xx2```\n",
    "    \n",
    "2. 각각의 은닉층 뉴런에서 시그모이드 함수를 지나게 되는데 시그모이드 함수가 리턴하는 결과값은 은닉층 뉴런의 최종 출력값이 된다.\n",
    "\n",
    "```h1 = sigmoid(z1)```\n",
    "```h2 = sigmoid(z2)```\n",
    "\n",
    "3. h1, h2 이 두 값은 다시 출력층의 뉴런으로 향하고 다시 각각의 값에 해당되는 가중치와 곱하고 다시 가중합되어 출력층 뉴런의 시그모이드 함수의 입력값이 된다.\n",
    "\n",
    "```z3 = W5Xh1 + W6Xh2```\n",
    "```z4 = W7Xh1 + W8Xh2```\n",
    "4. z3, z4가 출력층 뉴런에서 시그모이드 함수를 지난 값은 이 인공 신경망이 최종적으로 계산한 출력값으로 실제값을 예측하기 위한 값으로서 예측값이다.\n",
    "\n",
    "```o1 = sigmoid(z3)```\n",
    "```o2 = sigmoid(z4)```\n",
    "5. 예측값과 실제값의 오차를 계산하기 위한 오차 함수 선택, 손실 함수로는 평균 제곱 오차 MSE 사용.(실제값을 target, 예측값을 output)\n",
    "\n",
    "```Eo1 = 1/2(targeto1 - outputo1)2```\n",
    "```Eo2 = 1/2(targeto2 - outputo2)2```\n",
    "```Etotal = Eo1 + Eo2```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 역전파 1단계(BackPropagation Step 1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
