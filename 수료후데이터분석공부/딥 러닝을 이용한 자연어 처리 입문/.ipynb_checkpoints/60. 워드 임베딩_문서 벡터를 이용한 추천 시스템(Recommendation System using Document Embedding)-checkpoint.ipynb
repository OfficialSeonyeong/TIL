{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어떤 다수의 문장 또는 문서를 가지고 있다고 가정할 때, 이 문서들이 서로 얼마나 유사한지 비교하기 위해서는 각 문서를 문서 벡터로 변환하여야 할 것이다. 이미 구현한 패키지인 Doc2Vec이나 Sent2Vec 등을 사용하여 훈련하는 방법이 존재하지만, 가장 간단한 방법은 **문서에 존재하는 단어 벡터들의 평균을 구하는 것**이다.\n",
    "\n",
    "이번 챕터에서는 문서 내 각 단어들을 Word2Vec을 통해 단어 벡터로 변환하고, 이들의 평균으로 문서 벡터를 구하여 선호하는 도서와 유사한 도서를 찾아주는 도서 추천 시스템을 만들어 보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import urllib.request\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import requests\n",
    "import re\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import nltk\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 수:  2382\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./data/book_information.csv')\n",
    "print('전체 문서의 수: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Desc</th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>author</th>\n",
       "      <th>genre</th>\n",
       "      <th>image_link</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>We know that power is shifting: From West to E...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Moisés Naím</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.63</td>\n",
       "      <td>The End of Power: From Boardrooms to Battlefie...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Following the success of The Accidental Billio...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Blake J. Harris</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.94</td>\n",
       "      <td>Console Wars: Sega, Nintendo, and the Battle t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>How to tap the power of social software and ne...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Chris Brogan</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>3.78</td>\n",
       "      <td>Trust Agents: Using the Web to Build Influence...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>William J. Bernstein is an American financial ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>William J. Bernstein</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.20</td>\n",
       "      <td>The Four Pillars of Investing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Amazing book. And I joined Steve Jobs and many...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Akio Morita</td>\n",
       "      <td>Business</td>\n",
       "      <td>https://i.gr-assets.com/images/S/compressed.ph...</td>\n",
       "      <td>4.05</td>\n",
       "      <td>Made in Japan: Akio Morita and Sony</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               Desc  \\\n",
       "0           0  We know that power is shifting: From West to E...   \n",
       "1           1  Following the success of The Accidental Billio...   \n",
       "2           2  How to tap the power of social software and ne...   \n",
       "3           3  William J. Bernstein is an American financial ...   \n",
       "4           4  Amazing book. And I joined Steve Jobs and many...   \n",
       "\n",
       "   Unnamed: 0.1                author     genre  \\\n",
       "0           0.0           Moisés Naím  Business   \n",
       "1           1.0       Blake J. Harris  Business   \n",
       "2           2.0          Chris Brogan  Business   \n",
       "3           3.0  William J. Bernstein  Business   \n",
       "4           4.0           Akio Morita  Business   \n",
       "\n",
       "                                          image_link  rating  \\\n",
       "0  https://i.gr-assets.com/images/S/compressed.ph...    3.63   \n",
       "1  https://i.gr-assets.com/images/S/compressed.ph...    3.94   \n",
       "2  https://i.gr-assets.com/images/S/compressed.ph...    3.78   \n",
       "3  https://i.gr-assets.com/images/S/compressed.ph...    4.20   \n",
       "4  https://i.gr-assets.com/images/S/compressed.ph...    4.05   \n",
       "\n",
       "                                               title  \n",
       "0  The End of Power: From Boardrooms to Battlefie...  \n",
       "1  Console Wars: Sega, Nintendo, and the Battle t...  \n",
       "2  Trust Agents: Using the Web to Build Influence...  \n",
       "3                      The Four Pillars of Investing  \n",
       "4                Made in Japan: Akio Morita and Sony  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 전처리\n",
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words('english'))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "    \n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'[a-zA-Z]+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "df['cleaned'] = df['Desc'].apply(_removeNonAscii)\n",
    "df['cleaned'] = df.cleaned.apply(make_lower_case)\n",
    "df['cleaned'] = df.cleaned.apply(remove_stop_words)\n",
    "df['cleaned'] = df.cleaned.apply(remove_punctuation)\n",
    "df['cleaned'] = df.cleaned.apply(remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    know power shifting west east north south pres...\n",
       "1    following success accidental billionaires mone...\n",
       "2    tap power social software networks build busin...\n",
       "3    william j bernstein american financial theoris...\n",
       "4    amazing book joined steve jobs many akio morit...\n",
       "Name: cleaned, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['cleaned'][:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "전체 문서의 수:  2381\n"
     ]
    }
   ],
   "source": [
    "# 빈 값이 생긴 행이 있다면 NAN으로 변환 후 해당 행 제거\n",
    "df['cleaned'].replace('', np.nan, inplace=True)\n",
    "df = df[df['cleaned'].notna()]\n",
    "print('전체 문서의 수: ', len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토큰화를 수행해 corpus 만들기\n",
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 사전 훈련된 워드 임베딩 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('data/GoogleNews-vectors-negative300.bin.gz',\n",
       " <http.client.HTTPMessage at 0x192bb4a7248>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사전 훈련된 Word2Vec 다운\n",
    "urllib.request.urlretrieve(\"https://s3.amazonaws.com/dl4j-distribution/GoogleNews-vectors-negative300.bin.gz\", \\\n",
    "                           filename=\"data/GoogleNews-vectors-negative300.bin.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.word2vec import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "model = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', binary=True)\n",
    "model.wv.save_word2vec_format('googlenews.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_model = Word2Vec(size=300, window=5, min_count=2, workers=-1)\n",
    "word2vec_model.build_vocab(corpus)\n",
    "word2vec_model.intersect_word2vec_format('data/GoogleNews-vectors-negative300.bin.gz', lockf=1.0, binary=True)\n",
    "word2vec_model.train(corpus, total_examples = word2vec_model.corpus_count, epochs=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 단어 벡터의 평균 구하기\n",
    "각 문서에 존재하는 단어들의 벡터값의 평균을 구하여 해당 문서의 벡터값을 연산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectors(document_list):\n",
    "    document_embedding_list = []\n",
    "    \n",
    "    # 각 문서에 대하여\n",
    "    for line in document_embedding_list:\n",
    "        doc2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in word2vec_model.wv.vocab:\n",
    "                count += 1\n",
    "                # 해당 문서에 있는 모든 단어들의 벡터값을 더한다.\n",
    "                if doc2vec is None:\n",
    "                    doc2vec = word2vec_model[word]\n",
    "                else:\n",
    "                    doc2vec = doc2vec + word2vec_model[word]\n",
    "                    \n",
    "        if doc2vec is not None:\n",
    "            # 단어 벡터를 모두 더한 벡터의 값을 문서 길이로 나눈다.\n",
    "            doc2vec = doc2vec / count\n",
    "            document_embedding_list.append(doc2vec)\n",
    "            \n",
    "    # 각 문서에 대한 문서 벡터 리스트를 리턴\n",
    "    return document_embedding_list            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문서 벡터의 수:  0\n"
     ]
    }
   ],
   "source": [
    "document_embedding_list = vectors(df['cleaned'])\n",
    "print('문서 벡터의 수: ', len(document_embedding_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 추천 시스템 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 각 문서 벡터 간의 코사인 유사도\n",
    "cosine_similarities = cosine_similarity(document_embedding_list, document_embedding_list)\n",
    "print('코사인 유사도 매트릭스의 크기 :',cosine_similarities.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 가장 줄거리가 유사한 5개의 책을 찾아내는 함수\n",
    "def recommandations(title):\n",
    "    books = df[['title','image_link']]\n",
    "    \n",
    "    # 책의 제목을 입력하면 해당 제목의 인덱스를 리턴받아 idx에 저장\n",
    "    indices = pd.Series(df.index, index = df['title']).drop_duplicates()\n",
    "    idx = indices[title]\n",
    "    \n",
    "    # 입력된 책과 줄거리(document embedding)가 유사한 책 5개 선정\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:6]\n",
    "    \n",
    "    # 가장 유사한 책 5권의 인덱스\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    \n",
    "    # 전체 데이터프레임에서 해당 인덱스의 행만 추출\n",
    "    recommend = books.iloc[book_indices].reset_index(drop=True)\n",
    "    \n",
    "    fig = plt.figure(figsize=(20,30))\n",
    "    \n",
    "    # 데이터프레임으로부터 순차적으로 이미지를 출력\n",
    "    for index, row in recommand.iterrows():\n",
    "        response = requests.get(row['image_link'])\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        fig.add_sbplot(1,5,index+1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(row['title'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title\n",
       "The End of Power: From Boardrooms to Battlefields and Churches to States, Why Being In Charge Isn't What It Used to Be       0\n",
       "Console Wars: Sega, Nintendo, and the Battle that Defined a Generation                                                       1\n",
       "Trust Agents: Using the Web to Build Influence, Improve Reputation, and Earn Trust                                           2\n",
       "The Four Pillars of Investing                                                                                                3\n",
       "Made in Japan: Akio Morita and Sony                                                                                          4\n",
       "                                                                                                                          ... \n",
       "Insomnia                                                                                                                  2377\n",
       "Murder at the Vicarage                                                                                                    2378\n",
       "The Day of the Triffids                                                                                                   2379\n",
       "A Good Man is Hard to Find and Other Stories                                                                              2380\n",
       "Angela's Ashes                                                                                                            2381\n",
       "Length: 2381, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations(\"The Da Vinci Code\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
