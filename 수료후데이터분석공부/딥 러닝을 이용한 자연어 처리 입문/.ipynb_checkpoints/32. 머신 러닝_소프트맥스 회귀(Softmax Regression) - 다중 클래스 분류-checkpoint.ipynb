{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3개 이상의 선택지 중에서 1개를 고르는 다중 클래스 분류 문제를 위한 **소프트맥스 회귀(Softmax Regression)**\n",
    "\n",
    "## 1. 다중 클래스 분류(Multi-class Classification)\n",
    "이진 분류에서 사용한 시그모이드 함수는 0과 1사이의 출력값을 확률로 해석했다.이번에는 세 개 이상의 정답지에서 고르는 문제이다. 이 전체의 확률의 합계가 1이 되도록 하는 전체 정답지에 걸친 확률로 해석하는 것이 소프트맥스 함수이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 소프트맥스 함수(Softmax function)\n",
    "소프트맥스 함수는 분류해야하는 정답지(클래스)의 총 개수를 k라고 할 때, k차원의 벡터를 입력받아 각 클래스에 대한 확률을 추정한다.\n",
    "\n",
    "#### 소프트맥스 함수의 입력\n",
    "소프트맥스의 함수의 입력으로 사용되는 벡터는 벡터의 차원이 분류하고자 하는 클래스의 개수가 되어야 하기 때문에 입력 벡터 z의 차원수만큼 결과값이 나오도록 가중치 곱을 진행한다.\n",
    "\n",
    "#### 오차 계산 방법\n",
    "예측값과 비교를 할 수 있도록 실제값을 원-핫 벡터로 표현한다. 오차로부터 가중치를 업데이트한다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 원-핫 벡터의 무작위성\n",
    "* 꼭 실제값을 원-핫 벡터로 표현해야만 다중 클래스 분류 문제를 풀 수 있는 것은 아니지만, 대부분의 다중 클래스 분류 문제가 각 클래스 간의 관계가 균등하다는 점에서 원-핫 벡터는 이러한 점을 표현할 수 있는 적절한 표현 방법이다.\n",
    "* 레이블의 개수만큼 정수 인코딩을 하는 것이 편할 것이라고 직관적으로 생각이 될 수 있지만, 오차 크기를 계산하는 과정에 정수 크기가 반영되어 잘못된 정보가 반영된다. 그래서 거리가 모두 동일하게 표현되는 원-핫 벡터가 적절하다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
