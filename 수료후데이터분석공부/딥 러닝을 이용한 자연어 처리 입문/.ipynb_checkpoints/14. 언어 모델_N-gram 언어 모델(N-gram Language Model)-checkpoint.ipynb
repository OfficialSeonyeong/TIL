{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "일부 단어만 고려하는 접근 방법 (n-gram에서의 n이 단어의 개수 의미)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 코퍼스에서 카운트하지 못하는 경우의 감소\n",
    "* SLM의 한계는 훈련 코퍼스에 확률을 계산하고 싶은 문장이나 단어가 없을 수 있다는 점\n",
    "* 그런데 참고하는 단어들을 줄이면 카운트를 할 수 있는 가능성을 높일 수 있다. =>  P(is|An adorable little boy)≈ P(is|boy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. N-gram\n",
    "* 임의의 개수를 정하기 위한 기준\n",
    "* n개의 연속적인 단어 나열\n",
    "* unigram, bigram, trigram, 4-grams, 5-grams ...\n",
    "* 다음에 나올 단어의 예측은 오직 n-1 개의 단어에만 의존\n",
    "* n=4일때, P(w|boy is spreading)=count(boy is spreading w) / count(boy is spreading)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. N-gram Language Model의 한계\n",
    "* 주어진 문장에서 앞에 있던 단어인 '작고 사랑스러운(an adorable little)'이라는 수식어를 고려했다면 **작고 사랑스러운 소년**이 하는 행동을 긍정적인 내용으로 선택할 것이다. 하지만 N-gram은 이를 고려하지 못한다.\n",
    "* 문맥의 앞과 뒤 연결이 어렵다.\n",
    "\n",
    "(1) 희소 문제(Sparsity Problem)\n",
    "* 일부 단어만을 고려해 코퍼스에서 카운트 할 수 있는 확률을 높였지만, 여전히 희소 문제가 존재\n",
    "\n",
    "(2) n을 선택하는 것은 trade-off 문제\n",
    "* n을 크게 선택하면 실제 훈련 코퍼스에서 해당 n-gram을 카운트할 수 있는 확률은 적어지므로 희소 문제는 점점 심각해진다. 또한 n이 커질수록 모델 사이즈가 커진다는 문제점도 있다. 기본적으로 코퍼스의 모든 n-gram에 대해서 카운트를 해야 하기 때문이다.\n",
    "* n을 작게 선택하면 훈련 코퍼스에서 카운트는 잘 되겠지만 근사의 정확도는 현실의 확률분포와 멀어진다. \n",
    "* trade-off 문제로 인해 정확도를 높이려면 n은 최대 5를 넘게 잡아서는 안 된다고 권장된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 적용 분야(Domain)에 맞는 코퍼스의 수집\n",
    "* 어떤 분야인지, 어떤 어플리케이션인지에 따라서 특정 단어들의 확률 분포는 당연히 다르다.\n",
    "* 이를 언어 모델의 약점이라고 하는 경우도 있는데, 훈련에 사용된 도메인 코퍼스가 무엇이냐에 따라서 성능이 비약적으로 달라지기 때문"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 인공 신경망을 이용한 언어 모델(Neural Network Based Language Model)\n",
    "*  N-gram Language Model의 한계점을 극복하기위해 분모, 분자에 숫자를 더해서 카운트했을 때 0이 되는 것을 방지하는 등의 여러 일반화(generalization) 방법들이 존재 -> 그럼에도 취약점 해결 불가능\n",
    "* 대안으로 인공 신경망을 이용한 언어 모델이 많이 사용"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
