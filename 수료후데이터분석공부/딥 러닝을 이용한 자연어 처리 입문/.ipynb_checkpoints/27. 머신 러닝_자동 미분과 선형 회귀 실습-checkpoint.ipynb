{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**선형 회귀를 텐서플로우와 케라스를 통한 구현**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 자동 미분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tape_gradient()은 자동 미분 기능 수행\n",
    "# 2w2+5 라는 식을 세우고 w에 대해 미분하기\n",
    "w = tf.Variable(2.)\n",
    "\n",
    "def f(w):\n",
    "    y=w**2\n",
    "    z=2*y+5\n",
    "    return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<tf.Tensor: shape=(), dtype=float32, numpy=8.0>]\n"
     ]
    }
   ],
   "source": [
    "with tf.GradientTape() as tape:\n",
    "    z = f(w)\n",
    "    \n",
    "gradients = tape.gradient(z,[w])\n",
    "print(gradients)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 자동 미분을 이용한 선형 회귀 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습될 가중치 변수를 선언\n",
    "W = tf.Variable(4.0)\n",
    "b = tf.Variable(1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def hypothesis(x):\n",
    "    return W*x+b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15. 21. 23. 25.]\n"
     ]
    }
   ],
   "source": [
    "x_test = [3.5,5,5.5,6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 평균 제곱 오차를 손실 함수로 정의\n",
    "@tf.function\n",
    "def mse_loss(y_pred, y):\n",
    "    # 두 개의 차이값을 제곱을 해서 평균을 취한다.\n",
    "    return tf.reduce_mean(tf.square(y_pred - y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x와 y가 약 10배 차이가 나는 데이터 사용\n",
    "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
    "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑된 성적"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 옵티마이저는 경사 하강법, 학습률(learning rate=0.01)\n",
    "optimizer = tf.optimizers.SGD(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :   0 | W의 값 : 10.4581 | b의 값 : 2.001 | cost : 1.687088\n",
      "epoch :  10 | W의 값 : 10.5002 | b의 값 : 1.958 | cost : 1.341748\n",
      "epoch :  20 | W의 값 : 10.5076 | b의 값 : 1.911 | cost : 1.319475\n",
      "epoch :  30 | W의 값 : 10.5147 | b의 값 : 1.867 | cost : 1.298961\n",
      "epoch :  40 | W의 값 : 10.5215 | b의 값 : 1.824 | cost : 1.280066\n",
      "epoch :  50 | W의 값 : 10.5280 | b의 값 : 1.783 | cost : 1.262668\n",
      "epoch :  60 | W의 값 : 10.5343 | b의 값 : 1.743 | cost : 1.246642\n",
      "epoch :  70 | W의 값 : 10.5403 | b의 값 : 1.706 | cost : 1.231880\n",
      "epoch :  80 | W의 값 : 10.5461 | b의 값 : 1.669 | cost : 1.218294\n",
      "epoch :  90 | W의 값 : 10.5516 | b의 값 : 1.635 | cost : 1.205772\n",
      "epoch : 100 | W의 값 : 10.5569 | b의 값 : 1.601 | cost : 1.194246\n",
      "epoch : 110 | W의 값 : 10.5620 | b의 값 : 1.569 | cost : 1.183623\n",
      "epoch : 120 | W의 값 : 10.5669 | b의 값 : 1.538 | cost : 1.173846\n",
      "epoch : 130 | W의 값 : 10.5716 | b의 값 : 1.509 | cost : 1.164841\n",
      "epoch : 140 | W의 값 : 10.5761 | b의 값 :  1.48 | cost : 1.156546\n",
      "epoch : 150 | W의 값 : 10.5804 | b의 값 : 1.453 | cost : 1.148907\n",
      "epoch : 160 | W의 값 : 10.5846 | b의 값 : 1.427 | cost : 1.141875\n",
      "epoch : 170 | W의 값 : 10.5885 | b의 값 : 1.402 | cost : 1.135395\n",
      "epoch : 180 | W의 값 : 10.5924 | b의 값 : 1.378 | cost : 1.129426\n",
      "epoch : 190 | W의 값 : 10.5960 | b의 값 : 1.355 | cost : 1.123933\n",
      "epoch : 200 | W의 값 : 10.5996 | b의 값 : 1.333 | cost : 1.118870\n",
      "epoch : 210 | W의 값 : 10.6029 | b의 값 : 1.311 | cost : 1.114208\n",
      "epoch : 220 | W의 값 : 10.6062 | b의 값 : 1.291 | cost : 1.109911\n",
      "epoch : 230 | W의 값 : 10.6093 | b의 값 : 1.271 | cost : 1.105961\n",
      "epoch : 240 | W의 값 : 10.6123 | b의 값 : 1.253 | cost : 1.102319\n",
      "epoch : 250 | W의 값 : 10.6151 | b의 값 : 1.235 | cost : 1.098965\n",
      "epoch : 260 | W의 값 : 10.6179 | b의 값 : 1.217 | cost : 1.095878\n",
      "epoch : 270 | W의 값 : 10.6205 | b의 값 : 1.201 | cost : 1.093032\n",
      "epoch : 280 | W의 값 : 10.6231 | b의 값 : 1.185 | cost : 1.090411\n",
      "epoch : 290 | W의 값 : 10.6255 | b의 값 :  1.17 | cost : 1.087996\n",
      "epoch : 300 | W의 값 : 10.6278 | b의 값 : 1.155 | cost : 1.085775\n"
     ]
    }
   ],
   "source": [
    "# 약 300번에 걸쳐 경사 하강법 수행\n",
    "for i in range(301):\n",
    "    with tf.GradientTape() as tape:\n",
    "        # 현재 파라미터에 기반한 입력 x에 대한 예측값 y_pred\n",
    "        y_pred = hypothesis(X)\n",
    "        \n",
    "        # 평균 제곱 오차를 계산\n",
    "        cost = mse_loss(y_pred, y)\n",
    "        \n",
    "        # 손실 함수에 대한 파라미터의 미분값 계산\n",
    "        gradients = tape.gradient(cost, [W, b])\n",
    "        \n",
    "        # 파라미터 업데이트\n",
    "        optimizer.apply_gradients(zip(gradients, [W, b]))\n",
    "        \n",
    "        if i % 10 == 0:\n",
    "            print(\"epoch : {:3} | W의 값 : {:5.4f} | b의 값 : {:5.4} | cost : {:5.6f}\".format(i, W.numpy(), b.numpy(), cost))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[38.352215 54.29395  59.60786  64.921776]\n"
     ]
    }
   ],
   "source": [
    "# 임의의 값 예측\n",
    "x_test = [3.5, 5, 5.5, 6]\n",
    "print(hypothesis(x_test).numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 케라스로 구현하는 선형 회귀\n",
    "Sequential로 model이라는 이름의 모델을 만들고, 그리고 add를 통해 입력과 출력 벡터의 차원과 같은 필요한 정보 추가\n",
    "\n",
    "```model = keras.models.Sequential()```\n",
    "\n",
    "```model.add(keras.layers.Dense(1, input_dim=1))```\n",
    "\n",
    "* 첫번째 인자인 1은 출력의 차원을 정의하며, 두번째 인자인 input_dim은 입력의 차원을 정의\n",
    "* 이번 실습과 같이 1개의 실수 x를 가지고 1개의 실수 y를 예측하는 단순 선형 회귀를 구현하는 경우에는 각각 1의 값을 가진다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras import optimizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 486.9086 - mse: 486.9086\n",
      "Epoch 2/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.2226 - mse: 2.2226\n",
      "Epoch 3/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.2028 - mse: 2.2028\n",
      "Epoch 4/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 2.1838 - mse: 2.1838\n",
      "Epoch 5/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1656 - mse: 2.1656\n",
      "Epoch 6/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1481 - mse: 2.1481\n",
      "Epoch 7/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1313 - mse: 2.1313\n",
      "Epoch 8/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.1153 - mse: 2.1153\n",
      "Epoch 9/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0998 - mse: 2.0998\n",
      "Epoch 10/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0850 - mse: 2.0850\n",
      "Epoch 11/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0708 - mse: 2.0708\n",
      "Epoch 12/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0572 - mse: 2.0572\n",
      "Epoch 13/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0440 - mse: 2.0440\n",
      "Epoch 14/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0314 - mse: 2.0314\n",
      "Epoch 15/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0193 - mse: 2.0193\n",
      "Epoch 16/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 2.0077 - mse: 2.0077\n",
      "Epoch 17/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9965 - mse: 1.9965\n",
      "Epoch 18/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.9858 - mse: 1.9858\n",
      "Epoch 19/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9755 - mse: 1.9755\n",
      "Epoch 20/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9655 - mse: 1.9655\n",
      "Epoch 21/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9560 - mse: 1.9560\n",
      "Epoch 22/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.9468 - mse: 1.9468\n",
      "Epoch 23/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9380 - mse: 1.9380\n",
      "Epoch 24/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.9294 - mse: 1.9294\n",
      "Epoch 25/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9213 - mse: 1.9213\n",
      "Epoch 26/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9134 - mse: 1.9134\n",
      "Epoch 27/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.9058 - mse: 1.9058\n",
      "Epoch 28/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8985 - mse: 1.8985\n",
      "Epoch 29/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8915 - mse: 1.8915\n",
      "Epoch 30/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8847 - mse: 1.8847\n",
      "Epoch 31/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8782 - mse: 1.8782\n",
      "Epoch 32/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8719 - mse: 1.8719\n",
      "Epoch 33/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8659 - mse: 1.8659\n",
      "Epoch 34/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8600 - mse: 1.8600\n",
      "Epoch 35/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8544 - mse: 1.8544\n",
      "Epoch 36/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.8490 - mse: 1.8490\n",
      "Epoch 37/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.8438 - mse: 1.8438\n",
      "Epoch 38/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8388 - mse: 1.8388\n",
      "Epoch 39/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.9104 - mse: 2.910 - 0s 2ms/step - loss: 1.8339 - mse: 1.8339\n",
      "Epoch 40/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8293 - mse: 1.8293\n",
      "Epoch 41/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8248 - mse: 1.8248\n",
      "Epoch 42/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8204 - mse: 1.8204\n",
      "Epoch 43/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8163 - mse: 1.8163\n",
      "Epoch 44/300\n",
      "9/9 [==============================] - 0s 3ms/step - loss: 1.8122 - mse: 1.8122\n",
      "Epoch 45/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.8378 - mse: 2.837 - 0s 1ms/step - loss: 1.8083 - mse: 1.8083\n",
      "Epoch 46/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8046 - mse: 1.8046\n",
      "Epoch 47/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.8010 - mse: 1.8010\n",
      "Epoch 48/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1.7975 - mse: 1.7975\n",
      "Epoch 49/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7941 - mse: 1.7941\n",
      "Epoch 50/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7908 - mse: 1.7908\n",
      "Epoch 51/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7877 - mse: 1.7877\n",
      "Epoch 52/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7847 - mse: 1.7847\n",
      "Epoch 53/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7818 - mse: 1.7818\n",
      "Epoch 54/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7789 - mse: 1.7789\n",
      "Epoch 55/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7762 - mse: 1.7762\n",
      "Epoch 56/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7736 - mse: 1.7736\n",
      "Epoch 57/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7711 - mse: 1.7711\n",
      "Epoch 58/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7686 - mse: 1.7686\n",
      "Epoch 59/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7663 - mse: 1.7663\n",
      "Epoch 60/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7640 - mse: 1.7640\n",
      "Epoch 61/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7618 - mse: 1.7618\n",
      "Epoch 62/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7596 - mse: 1.7596\n",
      "Epoch 63/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7576 - mse: 1.7576\n",
      "Epoch 64/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7556 - mse: 1.7556\n",
      "Epoch 65/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7537 - mse: 1.7537\n",
      "Epoch 66/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7519 - mse: 1.7519\n",
      "Epoch 67/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7501 - mse: 1.7501\n",
      "Epoch 68/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7483 - mse: 1.7483\n",
      "Epoch 69/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7467 - mse: 1.7467\n",
      "Epoch 70/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7451 - mse: 1.7451\n",
      "Epoch 71/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7435 - mse: 1.7435\n",
      "Epoch 72/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7420 - mse: 1.7420\n",
      "Epoch 73/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7406 - mse: 1.7406\n",
      "Epoch 74/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7392 - mse: 1.7392\n",
      "Epoch 75/300\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.7378 - mse: 1.7378\n",
      "Epoch 76/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7365 - mse: 1.7365\n",
      "Epoch 77/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1.7353 - mse: 1.7353\n",
      "Epoch 78/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7340 - mse: 1.7340\n",
      "Epoch 79/300\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.7329 - mse: 1.7329\n",
      "Epoch 80/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7317 - mse: 1.7317\n",
      "Epoch 81/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7306 - mse: 1.7306\n",
      "Epoch 82/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7296 - mse: 1.7296\n",
      "Epoch 83/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7285 - mse: 1.7285\n",
      "Epoch 84/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7275 - mse: 1.7275\n",
      "Epoch 85/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7266 - mse: 1.7266\n",
      "Epoch 86/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7256 - mse: 1.7256\n",
      "Epoch 87/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7248 - mse: 1.7248\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 88/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7239 - mse: 1.7239\n",
      "Epoch 89/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7231 - mse: 1.7231\n",
      "Epoch 90/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7222 - mse: 1.7222\n",
      "Epoch 91/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7215 - mse: 1.7215\n",
      "Epoch 92/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7207 - mse: 1.7207\n",
      "Epoch 93/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7200 - mse: 1.7200\n",
      "Epoch 94/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7193 - mse: 1.7193\n",
      "Epoch 95/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7186 - mse: 1.7186\n",
      "Epoch 96/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7179 - mse: 1.7179\n",
      "Epoch 97/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7173 - mse: 1.7173\n",
      "Epoch 98/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7167 - mse: 1.7167\n",
      "Epoch 99/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7161 - mse: 1.7161\n",
      "Epoch 100/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7155 - mse: 1.7155\n",
      "Epoch 101/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7150 - mse: 1.7150\n",
      "Epoch 102/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7144 - mse: 1.7144\n",
      "Epoch 103/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7139 - mse: 1.7139\n",
      "Epoch 104/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7134 - mse: 1.7134\n",
      "Epoch 105/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.5643 - mse: 2.564 - 0s 2ms/step - loss: 1.7129 - mse: 1.7129\n",
      "Epoch 106/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7124 - mse: 1.7124\n",
      "Epoch 107/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7120 - mse: 1.7120\n",
      "Epoch 108/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7115 - mse: 1.7115\n",
      "Epoch 109/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 1.7111 - mse: 1.7111\n",
      "Epoch 110/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7107 - mse: 1.7107\n",
      "Epoch 111/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7103 - mse: 1.7103\n",
      "Epoch 112/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7099 - mse: 1.7099\n",
      "Epoch 113/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7096 - mse: 1.7096\n",
      "Epoch 114/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7092 - mse: 1.7092\n",
      "Epoch 115/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7089 - mse: 1.7089\n",
      "Epoch 116/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7085 - mse: 1.7085\n",
      "Epoch 117/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7082 - mse: 1.7082\n",
      "Epoch 118/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7079 - mse: 1.7079\n",
      "Epoch 119/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7076 - mse: 1.7076\n",
      "Epoch 120/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7073 - mse: 1.7073\n",
      "Epoch 121/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7070 - mse: 1.7070\n",
      "Epoch 122/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7067 - mse: 1.7067\n",
      "Epoch 123/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7065 - mse: 1.7065\n",
      "Epoch 124/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7062 - mse: 1.7062\n",
      "Epoch 125/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7060 - mse: 1.7060\n",
      "Epoch 126/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7057 - mse: 1.7057\n",
      "Epoch 127/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7055 - mse: 1.7055\n",
      "Epoch 128/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7053 - mse: 1.7053\n",
      "Epoch 129/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7051 - mse: 1.7051\n",
      "Epoch 130/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 1.7049 - mse: 1.7049\n",
      "Epoch 131/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7047 - mse: 1.7047\n",
      "Epoch 132/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7045 - mse: 1.7045\n",
      "Epoch 133/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7043 - mse: 1.7043\n",
      "Epoch 134/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7041 - mse: 1.7041\n",
      "Epoch 135/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7039 - mse: 1.7039\n",
      "Epoch 136/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7037 - mse: 1.7037\n",
      "Epoch 137/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7036 - mse: 1.7036\n",
      "Epoch 138/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7034 - mse: 1.7034\n",
      "Epoch 139/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7033 - mse: 1.7033\n",
      "Epoch 140/300\n",
      "9/9 [==============================] - 0s 997us/step - loss: 1.7031 - mse: 1.7031\n",
      "Epoch 141/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7030 - mse: 1.7030\n",
      "Epoch 142/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7028 - mse: 1.7028\n",
      "Epoch 143/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7027 - mse: 1.7027\n",
      "Epoch 144/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7026 - mse: 1.7026\n",
      "Epoch 145/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7024 - mse: 1.7024\n",
      "Epoch 146/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7023 - mse: 1.7023\n",
      "Epoch 147/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7022 - mse: 1.7022\n",
      "Epoch 148/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7021 - mse: 1.7021\n",
      "Epoch 149/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7020 - mse: 1.7020\n",
      "Epoch 150/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7019 - mse: 1.7019\n",
      "Epoch 151/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7018 - mse: 1.7018\n",
      "Epoch 152/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7017 - mse: 1.7017\n",
      "Epoch 153/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7016 - mse: 1.7016\n",
      "Epoch 154/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7015 - mse: 1.7015\n",
      "Epoch 155/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7014 - mse: 1.7014\n",
      "Epoch 156/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7013 - mse: 1.7013\n",
      "Epoch 157/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7012 - mse: 1.7012\n",
      "Epoch 158/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7011 - mse: 1.7011\n",
      "Epoch 159/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1.7011 - mse: 1.7011\n",
      "Epoch 160/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7010 - mse: 1.7010\n",
      "Epoch 161/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7009 - mse: 1.7009\n",
      "Epoch 162/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7008 - mse: 1.7008\n",
      "Epoch 163/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7008 - mse: 1.7008\n",
      "Epoch 164/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7007 - mse: 1.7007\n",
      "Epoch 165/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7006 - mse: 1.7006\n",
      "Epoch 166/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7006 - mse: 1.7006\n",
      "Epoch 167/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1.7005 - mse: 1.7005\n",
      "Epoch 168/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7005 - mse: 1.7005\n",
      "Epoch 169/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7004 - mse: 1.7004\n",
      "Epoch 170/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7003 - mse: 1.7003\n",
      "Epoch 171/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7003 - mse: 1.7003\n",
      "Epoch 172/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7002 - mse: 1.7002\n",
      "Epoch 173/300\n",
      "9/9 [==============================] - 0s 875us/step - loss: 1.7002 - mse: 1.7002\n",
      "Epoch 174/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 2ms/step - loss: 1.7001 - mse: 1.7001\n",
      "Epoch 175/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.7001 - mse: 1.7001\n",
      "Epoch 176/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7001 - mse: 1.7001\n",
      "Epoch 177/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7000 - mse: 1.7000\n",
      "Epoch 178/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.7000 - mse: 1.7000\n",
      "Epoch 179/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6999 - mse: 1.6999\n",
      "Epoch 180/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6999 - mse: 1.6999\n",
      "Epoch 181/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6998 - mse: 1.6998\n",
      "Epoch 182/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6998 - mse: 1.6998\n",
      "Epoch 183/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6998 - mse: 1.6998\n",
      "Epoch 184/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6997 - mse: 1.6997\n",
      "Epoch 185/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6997 - mse: 1.6997\n",
      "Epoch 186/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6997 - mse: 1.6997\n",
      "Epoch 187/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6996 - mse: 1.6996\n",
      "Epoch 188/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 1.6996 - mse: 1.6996\n",
      "Epoch 189/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6996 - mse: 1.6996\n",
      "Epoch 190/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6996 - mse: 1.6996\n",
      "Epoch 191/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6995 - mse: 1.6995\n",
      "Epoch 192/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6995 - mse: 1.6995\n",
      "Epoch 193/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 1.6995 - mse: 1.6995\n",
      "Epoch 194/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6995 - mse: 1.6995\n",
      "Epoch 195/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 196/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 197/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 198/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 199/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6994 - mse: 1.6994\n",
      "Epoch 200/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6993 - mse: 1.6993\n",
      "Epoch 201/300\n",
      "9/9 [==============================] - 0s 874us/step - loss: 1.6993 - mse: 1.6993\n",
      "Epoch 202/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6993 - mse: 1.6993\n",
      "Epoch 203/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6993 - mse: 1.6993\n",
      "Epoch 204/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6993 - mse: 1.6993\n",
      "Epoch 205/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 206/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 207/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 208/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 209/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 210/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6992 - mse: 1.6992\n",
      "Epoch 211/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 212/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 213/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.5243 - mse: 2.524 - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 214/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 215/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 216/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 217/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 218/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 219/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6991 - mse: 1.6991\n",
      "Epoch 220/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 221/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 222/300\n",
      "9/9 [==============================] - 0s 1000us/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 223/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 224/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 225/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 226/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 227/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 228/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 229/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 230/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 231/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6990 - mse: 1.6990\n",
      "Epoch 232/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 233/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 234/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 235/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 236/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 237/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 238/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 239/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 240/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 241/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 242/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 243/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 244/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 245/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 246/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 247/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 248/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 249/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 250/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6989 - mse: 1.6989\n",
      "Epoch 251/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 252/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 253/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 254/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 255/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 256/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 257/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 258/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 259/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 260/300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 261/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 262/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 263/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 264/300\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 265/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 266/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 267/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 268/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 269/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 270/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 271/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 272/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 273/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 274/300\n",
      "9/9 [==============================] - 0s 999us/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 275/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 276/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 277/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 278/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 279/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 280/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 281/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 282/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 283/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 284/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 285/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 286/300\n",
      "9/9 [==============================] - ETA: 0s - loss: 2.5233 - mse: 2.523 - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 287/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 288/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 289/300\n",
      "9/9 [==============================] - 0s 4ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 290/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 291/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 292/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 293/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 294/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 295/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 296/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 297/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 298/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 299/300\n",
      "9/9 [==============================] - 0s 1ms/step - loss: 1.6988 - mse: 1.6988\n",
      "Epoch 300/300\n",
      "9/9 [==============================] - 0s 2ms/step - loss: 1.6988 - mse: 1.6988\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1349348ee88>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=[1,2,3,4,5,6,7,8,9] # 공부하는 시간\n",
    "y=[11,22,33,44,53,66,77,87,95] # 각 공부하는 시간에 맵핑된 성적\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(1, input_dim=1, activation='linear'))\n",
    "# sgd는 경사 하강법 의미, 학습률(learning rate, lr)은 0.01\n",
    "sgd = optimizers.SGD(lr=0.01)\n",
    "# 손실 함수(Loss function)은 평균제곱오차 mse를 사용\n",
    "model.compile(optimizer=sgd, loss='mse', metrics=['mse'])\n",
    "\n",
    "# 주어진 X와 y 데이터에 대해 오차를 최소화하는 작업을 300번 진행\n",
    "model.fit(X,y, batch_size=1, epochs=300, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x13493803808>,\n",
       " <matplotlib.lines.Line2D at 0x134953fa148>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(X, model.predict(X), 'b', X,y, 'k.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[98.55646]]\n"
     ]
    }
   ],
   "source": [
    "print(model.predict([9.5]))\n",
    "# 9시간 30분을 공부하면 약 98.5점을 얻을 수 있다.(예측)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
