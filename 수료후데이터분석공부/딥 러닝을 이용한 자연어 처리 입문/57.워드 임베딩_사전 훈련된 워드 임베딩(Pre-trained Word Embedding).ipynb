{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"57.워드 임베딩_사전 훈련된 워드 임베딩(Pre-trained Word Embedding).ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyOdpfG6h3rD8UfCra8lnsKr"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"J9CGs4KPzlng"},"source":["**케라스의 임베딩 층(embedding layer)**과 **사전 훈련된 워드 임베딩(pre-trained word embedding)** 비교"]},{"cell_type":"markdown","metadata":{"id":"pf6BNj6Cz4Yu"},"source":["## 1. 케라스 임베딩 층(Keras Embedding layer)\n","\n","### 1) 임베딩 층은 룩업 테이블이다.\n","* 임베딩 층의 입력으로 사용하기 위해서 입력 시퀀스의 각 단어들은 모두 정수 인코딩이 되어 있어야 한다.\n","* 임베딩 층은 입력 정수에 대해 밀집 벡터(dense vector)로 맵핑하고 이 밀집 벡터는 인공 신경망의 학습 과정에서 가중치가 학습되는 것과 같은 방식으로 훈련된다.\n","* 특정 단어와 맵핑되는 정수를 인덱스로 가지는 테이블로부터 임베딩 벡터 값을 가져오는 룩업 테이블 = 임베딩 층\n","\n","```v = Embedding(vocab_size, output_dim, input_length)```\n","  * vocab_size : 텍스트 데이터의 전체 단어 집합의 크기\n","  * output_dim : 워드 임베딩 후의 임베딩 벡터의 차원\n","  * input_length : 입력 시퀀스의 길이\n","\n","\n","*Embedding()은 (number of samples, input_length)인 2D 정수 텐서를 입력받는다. 이 때 각 sample은 정수 인코딩이 된 결과로, 정수의 시퀀스. Embedding()은 워드 임베딩 작업을 수행하고 (number of samples, input_length, embedding word dimentionality)인 3D 실수 텐서를 리턴*\n"]},{"cell_type":"markdown","metadata":{"id":"8kyNdRJZ9BNv"},"source":["### 2) 임베딩 층 사용하기\n","*문장의 긍,부정을 판단하는 감성 분류 모델*"]},{"cell_type":"code","metadata":{"id":"UhGm6qmnzWH1","executionInfo":{"status":"ok","timestamp":1623765473856,"user_tz":-540,"elapsed":1228,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}}},"source":["from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","import numpy as np"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"mWWr70vE9qyE","executionInfo":{"status":"ok","timestamp":1623765539569,"user_tz":-540,"elapsed":252,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}}},"source":["# 긍정 문장은 1, 부정 문장은 0\n","sentences = ['nice great best amazing', 'stop lies', 'pitiful nerd', 'excellent work', 'supreme quality', 'bad', 'highly respectable']\n","y_train = [1, 0, 0, 1, 1, 0, 1]"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"BifWqyU299h6","executionInfo":{"status":"ok","timestamp":1623765572426,"user_tz":-540,"elapsed":239,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"1b362daa-1211-4fea-95fc-27b3eba511c1"},"source":["t = Tokenizer()\n","t.fit_on_texts(sentences)\n","vocab_size = len(t.word_index)+1\n","\n","print(vocab_size)"],"execution_count":3,"outputs":[{"output_type":"stream","text":["16\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"j1r-Zgpv-Fjo","executionInfo":{"status":"ok","timestamp":1623765738080,"user_tz":-540,"elapsed":244,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"bac80621-6303-40d2-d0f8-128123f35acc"},"source":["# 정수 인코딩\n","X_encoded = t.texts_to_sequences(sentences)\n","print(X_encoded)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["[[1, 2, 3, 4], [5, 6], [7, 8], [9, 10], [11, 12], [13], [14, 15]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"MskXVaTe-Nrz","executionInfo":{"status":"ok","timestamp":1623765744850,"user_tz":-540,"elapsed":254,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"075e70e9-2ebc-40e5-c13c-a5ba27544784"},"source":["max_len = max(len(l) for l in X_encoded)\n","print(max_len)"],"execution_count":7,"outputs":[{"output_type":"stream","text":["4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"nXD9k0iz-YFz","executionInfo":{"status":"ok","timestamp":1623765784441,"user_tz":-540,"elapsed":245,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"8d792b25-88b8-4290-a7a1-f944a943e056"},"source":["# 패딩\n","X_train = pad_sequences(X_encoded, maxlen=max_len, padding='post')\n","y_train = np.array(y_train)\n","print(X_train)"],"execution_count":8,"outputs":[{"output_type":"stream","text":["[[ 1  2  3  4]\n"," [ 5  6  0  0]\n"," [ 7  8  0  0]\n"," [ 9 10  0  0]\n"," [11 12  0  0]\n"," [13  0  0  0]\n"," [14 15  0  0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"SX7WwS4X-5Sj","executionInfo":{"status":"ok","timestamp":1623765888478,"user_tz":-540,"elapsed":283,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}}},"source":["# 모델 설계\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Flatten\n","\n","model = Sequential()\n","model.add(Embedding(vocab_size, 4, input_length=max_len))\n","model.add(Flatten()) # # Dense의 입력으로 넣기위함\n","model.add(Dense(1, activation='sigmoid')) # 이진 분류"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"K4WV73DK_StP","executionInfo":{"status":"ok","timestamp":1623765983524,"user_tz":-540,"elapsed":613,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"3283192f-4760-4467-da92-2e1a3077d98c"},"source":["model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","model.fit(X_train, y_train, epochs=5, verbose=2)"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1/1 - 0s - loss: 0.4940 - acc: 1.0000\n","Epoch 2/5\n","1/1 - 0s - loss: 0.4921 - acc: 1.0000\n","Epoch 3/5\n","1/1 - 0s - loss: 0.4902 - acc: 1.0000\n","Epoch 4/5\n","1/1 - 0s - loss: 0.4882 - acc: 1.0000\n","Epoch 5/5\n","1/1 - 0s - loss: 0.4863 - acc: 1.0000\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc22f323250>"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"markdown","metadata":{"id":"Gn_VbUcl_sRC"},"source":["## 2. 사전 훈련된 워드 임베딩(Pre-Trained Word Embedding) 사용하기\n","훈련 데이터가 적은 상황이라면 모델에 케라스의 Embedding()을 사용하는 것보다 다른 텍스트 데이터로 사전 훈련되어 있는 임베딩 벡터를 불러오는 것이 나은 선택일 수 있다."]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"iCAXp6Ih_kba","executionInfo":{"status":"ok","timestamp":1623766200333,"user_tz":-540,"elapsed":267,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"ff6f6443-1837-48cd-9835-cfa821d0a800"},"source":["print(X_train)"],"execution_count":12,"outputs":[{"output_type":"stream","text":["[[ 1  2  3  4]\n"," [ 5  6  0  0]\n"," [ 7  8  0  0]\n"," [ 9 10  0  0]\n"," [11 12  0  0]\n"," [13  0  0  0]\n"," [14 15  0  0]]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"N3VLO6ZMAe2H","executionInfo":{"status":"ok","timestamp":1623766206478,"user_tz":-540,"elapsed":246,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"2e39112d-5826-4050-8e3f-9a59dc1b4ac8"},"source":["print(y_train)"],"execution_count":13,"outputs":[{"output_type":"stream","text":["[1 0 0 1 1 0 1]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"qD-ZhqIzA-Zi"},"source":["### 1) 사전 훈련된 GloVe 사용하기"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"24bqX_8JAgWT","executionInfo":{"status":"ok","timestamp":1623766508044,"user_tz":-540,"elapsed":184894,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"ec1d202b-0191-4525-f983-390b1fb82828"},"source":["!wget http://nlp.stanford.edu/data/glove.6B.zip\n","!unzip glove*.zip"],"execution_count":14,"outputs":[{"output_type":"stream","text":["--2021-06-15 14:12:02--  http://nlp.stanford.edu/data/glove.6B.zip\n","Resolving nlp.stanford.edu (nlp.stanford.edu)... 171.64.67.140\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:80... connected.\n","HTTP request sent, awaiting response... 302 Found\n","Location: https://nlp.stanford.edu/data/glove.6B.zip [following]\n","--2021-06-15 14:12:03--  https://nlp.stanford.edu/data/glove.6B.zip\n","Connecting to nlp.stanford.edu (nlp.stanford.edu)|171.64.67.140|:443... connected.\n","HTTP request sent, awaiting response... 301 Moved Permanently\n","Location: http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip [following]\n","--2021-06-15 14:12:03--  http://downloads.cs.stanford.edu/nlp/data/glove.6B.zip\n","Resolving downloads.cs.stanford.edu (downloads.cs.stanford.edu)... 171.64.64.22\n","Connecting to downloads.cs.stanford.edu (downloads.cs.stanford.edu)|171.64.64.22|:80... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 862182613 (822M) [application/zip]\n","Saving to: ‘glove.6B.zip’\n","\n","glove.6B.zip        100%[===================>] 822.24M  5.16MB/s    in 2m 40s  \n","\n","2021-06-15 14:14:42 (5.15 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n","\n","Archive:  glove.6B.zip\n","  inflating: glove.6B.50d.txt        \n","  inflating: glove.6B.100d.txt       \n","  inflating: glove.6B.200d.txt       \n","  inflating: glove.6B.300d.txt       \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GQ5D7EHDA85A","executionInfo":{"status":"ok","timestamp":1623766516716,"user_tz":-540,"elapsed":239,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"3a3af9af-8a81-4007-9b69-94e03064ac64"},"source":["n = 0\n","f = open('glove.6B.100d.txt', encoding='utf8')\n","\n","for line in f:\n","  word_vector = line.split()\n","  print(word_vector)\n","  word = word_vector[0]\n","  print(word)\n","  n=n+1\n","  if n == 2:\n","    break\n","\n","f.close()"],"execution_count":15,"outputs":[{"output_type":"stream","text":["['the', '-0.038194', '-0.24487', '0.72812', '-0.39961', '0.083172', '0.043953', '-0.39141', '0.3344', '-0.57545', '0.087459', '0.28787', '-0.06731', '0.30906', '-0.26384', '-0.13231', '-0.20757', '0.33395', '-0.33848', '-0.31743', '-0.48336', '0.1464', '-0.37304', '0.34577', '0.052041', '0.44946', '-0.46971', '0.02628', '-0.54155', '-0.15518', '-0.14107', '-0.039722', '0.28277', '0.14393', '0.23464', '-0.31021', '0.086173', '0.20397', '0.52624', '0.17164', '-0.082378', '-0.71787', '-0.41531', '0.20335', '-0.12763', '0.41367', '0.55187', '0.57908', '-0.33477', '-0.36559', '-0.54857', '-0.062892', '0.26584', '0.30205', '0.99775', '-0.80481', '-3.0243', '0.01254', '-0.36942', '2.2167', '0.72201', '-0.24978', '0.92136', '0.034514', '0.46745', '1.1079', '-0.19358', '-0.074575', '0.23353', '-0.052062', '-0.22044', '0.057162', '-0.15806', '-0.30798', '-0.41625', '0.37972', '0.15006', '-0.53212', '-0.2055', '-1.2526', '0.071624', '0.70565', '0.49744', '-0.42063', '0.26148', '-1.538', '-0.30223', '-0.073438', '-0.28312', '0.37104', '-0.25217', '0.016215', '-0.017099', '-0.38984', '0.87424', '-0.72569', '-0.51058', '-0.52028', '-0.1459', '0.8278', '0.27062']\n","the\n","[',', '-0.10767', '0.11053', '0.59812', '-0.54361', '0.67396', '0.10663', '0.038867', '0.35481', '0.06351', '-0.094189', '0.15786', '-0.81665', '0.14172', '0.21939', '0.58505', '-0.52158', '0.22783', '-0.16642', '-0.68228', '0.3587', '0.42568', '0.19021', '0.91963', '0.57555', '0.46185', '0.42363', '-0.095399', '-0.42749', '-0.16567', '-0.056842', '-0.29595', '0.26037', '-0.26606', '-0.070404', '-0.27662', '0.15821', '0.69825', '0.43081', '0.27952', '-0.45437', '-0.33801', '-0.58184', '0.22364', '-0.5778', '-0.26862', '-0.20425', '0.56394', '-0.58524', '-0.14365', '-0.64218', '0.0054697', '-0.35248', '0.16162', '1.1796', '-0.47674', '-2.7553', '-0.1321', '-0.047729', '1.0655', '1.1034', '-0.2208', '0.18669', '0.13177', '0.15117', '0.7131', '-0.35215', '0.91348', '0.61783', '0.70992', '0.23955', '-0.14571', '-0.37859', '-0.045959', '-0.47368', '0.2385', '0.20536', '-0.18996', '0.32507', '-1.1112', '-0.36341', '0.98679', '-0.084776', '-0.54008', '0.11726', '-1.0194', '-0.24424', '0.12771', '0.013884', '0.080374', '-0.35414', '0.34951', '-0.7226', '0.37549', '0.4441', '-0.99059', '0.61214', '-0.35111', '-0.83155', '0.45293', '0.082577']\n",",\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"NgkJMQWyBeDc","executionInfo":{"status":"ok","timestamp":1623766536226,"user_tz":-540,"elapsed":243,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"36db3266-3870-4dfd-8357-ec8d1db2f4d0"},"source":["print(type(word_vector))\n","print(len(word_vector))"],"execution_count":16,"outputs":[{"output_type":"stream","text":["<class 'list'>\n","101\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"keUEd4G_CD8P"},"source":["첫번째 값은 임베딩 벡터가 의미하는 단어를 의미, 두번째 값부터 마지막 값은 해당 단어의 임베딩 벡터의 100개의 차원에서의 각 값"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbuuDfuaBw2q","executionInfo":{"status":"ok","timestamp":1623766759331,"user_tz":-540,"elapsed":11535,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"e03f183f-358a-4e9f-8ca7-554e905af3f1"},"source":["import numpy as np\n","embedding_dict = dict()\n","f = open('glove.6B.100d.txt', encoding=\"utf8\")\n","\n","for line in f:\n","  word_vector = line.split()\n","  word = word_vector[0]\n","  word_vector_arr = np.asarray(word_vector[1:], dtype='float32')\n","  embedding_dict[word] = word_vector_arr\n","f.close()\n","print('%s개의 Embedding vector가 있습니다.' % len(embedding_dict))"],"execution_count":17,"outputs":[{"output_type":"stream","text":["400000개의 Embedding vector가 있습니다.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q6OJXWigCkkh","executionInfo":{"status":"ok","timestamp":1623766784601,"user_tz":-540,"elapsed":237,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"7eb4d293-67a6-43e3-fe44-78bc3bec9c81"},"source":["print(embedding_dict['respectable'])\n","print(len(embedding_dict['respectable']))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["[-0.049773   0.19903    0.10585    0.1391    -0.32395    0.44053\n","  0.3947    -0.22805   -0.25793    0.49768    0.15384   -0.08831\n","  0.0782    -0.8299    -0.037788   0.16772   -0.45197   -0.17085\n","  0.74756    0.98256    0.81872    0.28507    0.16178   -0.48626\n"," -0.006265  -0.92469   -0.30625   -0.067318  -0.046762  -0.76291\n"," -0.0025264 -0.018795   0.12882   -0.52457    0.3586     0.43119\n"," -0.89477   -0.057421  -0.53724    0.25587    0.55195    0.44698\n"," -0.24252    0.29946    0.25776   -0.8717     0.68426   -0.05688\n"," -0.1848    -0.59352   -0.11227   -0.57692   -0.013593   0.18488\n"," -0.32507   -0.90171    0.17672    0.075601   0.54896   -0.21488\n"," -0.54018   -0.45882   -0.79536    0.26331    0.18879   -0.16363\n","  0.3975     0.1099     0.1164    -0.083499   0.50159    0.35802\n","  0.25677    0.088546   0.42108    0.28674   -0.71285   -0.82915\n","  0.15297   -0.82712    0.022112   1.067     -0.31776    0.1211\n"," -0.069755  -0.61327    0.27308   -0.42638   -0.085084  -0.17694\n"," -0.0090944  0.1109     0.62543   -0.23682   -0.44928   -0.3667\n"," -0.21616   -0.19187   -0.032502   0.38025  ]\n","100\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"u7UXdDcfCtf6","executionInfo":{"status":"ok","timestamp":1623766817087,"user_tz":-540,"elapsed":4,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"09d8c22f-f637-4316-bfd0-de6643b05ca6"},"source":["embedding_matrix = np.zeros((vocab_size, 100))\n","# 단어 집합 크기의 행과 100개의 열을 가지는 행렬 생성. 값은 전부 0으로 채워진다.\n","np.shape(embedding_matrix)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(16, 100)"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9lCRmz0gC1aE","executionInfo":{"status":"ok","timestamp":1623766843949,"user_tz":-540,"elapsed":239,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"58533e92-4967-4da0-adf9-f44fc3b27e4a"},"source":["print(t.word_index.items())"],"execution_count":20,"outputs":[{"output_type":"stream","text":["dict_items([('nice', 1), ('great', 2), ('best', 3), ('amazing', 4), ('stop', 5), ('lies', 6), ('pitiful', 7), ('nerd', 8), ('excellent', 9), ('work', 10), ('supreme', 11), ('quality', 12), ('bad', 13), ('highly', 14), ('respectable', 15)])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"HC4d88KqC7_E","executionInfo":{"status":"ok","timestamp":1623766921565,"user_tz":-540,"elapsed":245,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}}},"source":["for word, i in t.word_index.items():\n","  temp = embedding_dict.get(word) # 단어(key) 해당되는 임베딩 벡터의 100개의 값(value)를 임시 변수에 저장\n","  if temp is not None:\n","    embedding_matrix[i] = temp # 임수 변수의 값을 단어와 맵핑되는 인덱스의 행에 삽입"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"hg7PyaOiDO78","executionInfo":{"status":"ok","timestamp":1623767009298,"user_tz":-540,"elapsed":240,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}}},"source":["# 임베딩 층 만들기\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense, Embedding, Flatten\n","\n","model = Sequential()\n","e = Embedding(vocab_size, 100, weights=[embedding_matrix], input_length=max_len, trainable=False) # 사전 훈련된 워드 임베딩을 그대로 사용할 것이므로, 별도로 더 이상 훈련을 하지 않는다는 옵션"],"execution_count":23,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vLnM9Az9DfLp","executionInfo":{"status":"ok","timestamp":1623767044847,"user_tz":-540,"elapsed":669,"user":{"displayName":"윤선영","photoUrl":"","userId":"03257090453356543910"}},"outputId":"0fd9a957-c287-4d26-e378-489dc8849a0b"},"source":["model.add(e)\n","model.add(Flatten())\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])\n","model.fit(X_train, y_train, epochs=5, verbose=2)"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Epoch 1/5\n","1/1 - 0s - loss: 0.6330 - acc: 0.7143\n","Epoch 2/5\n","1/1 - 0s - loss: 0.6112 - acc: 0.7143\n","Epoch 3/5\n","1/1 - 0s - loss: 0.5902 - acc: 0.7143\n","Epoch 4/5\n","1/1 - 0s - loss: 0.5700 - acc: 0.7143\n","Epoch 5/5\n","1/1 - 0s - loss: 0.5507 - acc: 0.7143\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["<tensorflow.python.keras.callbacks.History at 0x7fc22913df50>"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"CelX8jEZEI_J"},"source":["### 2) 사전 훈련된 Word2Vec 사용하기\n"]},{"cell_type":"code","metadata":{"id":"KxFqwUuoDs7Y"},"source":[""],"execution_count":null,"outputs":[]}]}