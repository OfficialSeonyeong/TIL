{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 웹 크롤링 실습 및 csv 파일 작성과 이미지 스크랩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.error import HTTPError\n",
    "from urllib.error import URLError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.imdb.com/title/tt4154756/reviews?ref_=tt_ql_3'\n",
    "\n",
    "\n",
    "try:\n",
    "    html = urlopen(url)\n",
    "    \n",
    "except HTTPError as he :\n",
    "        print('http error')\n",
    "except URLError as ue:\n",
    "    print('url error')\n",
    "else:\n",
    "    soup= BeautifulSoup(html.read(),'html.parser', from_encoding='utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 점수(별점), 리뷰제목, 작성자 닉네임, 작성날짜, 리뷰내용\n",
    "* 감정분석(VADER) - NLTK\n",
    "- good +0.1, awful -0.1, perfect +0.2\n",
    "- 문장에서 해당 단어가 추출되면 나올 때마다 점수를 계산, 양수면 긍정, 음수면 부정으로 평가해보자"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "review_list = soup.find_all('div','imdb-user-review')\n",
    "review_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import tokenize\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "# 워드클라우드 띄울때 쓸 모든 리뷰 텍스트를 합친 문자열\n",
    "sum_review=''\n",
    "\n",
    "for review in review_list:\n",
    "    score = review.find('span').get_text()\n",
    "    score = score.split('/')[0].strip('\\n')\n",
    "    title = review.find('a').get_text().strip('\\n')\n",
    "    writer = review.find('span','display-name-link').get_text()\n",
    "    date = review.find('span', 'review-date').get_text()\n",
    "    content = review.find('div','text show-more__control').get_text().replace('\\n',' ')\n",
    "    \n",
    "    sum_review = sum_review+content\n",
    "    \n",
    " #   print(content)\n",
    "    lines_list = tokenize.sent_tokenize(content)\n",
    "    sum = 0\n",
    "    # polarity_scores(): 문장을 단어별로 분석해서 긍정, 부정, 중립에 대한 점수를 계산해주고 종합 점수(compound)를 반환\n",
    "    for sent in lines_list:\n",
    "        ss = sid.polarity_scores(sent)\n",
    "        sum = sum + ss['compound']\n",
    "    sum1 =str(sum/len(lines_list))\n",
    "    data.append([score, title, writer, date, content, sum1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open('./data/service_imdb_wordcloud2.csv','w', encoding='utf-8') as file:\n",
    "#     file.write('score, title, writer, date, cotent, sum \\n')\n",
    "    \n",
    "#     #data를 반복해서 저장\n",
    "#     for line in data:\n",
    "#         file.write(\"{},{},{},{},{},{}\\n\".format(line[0],line[1],line[2],line[3],line[4],line[5]))\n",
    "\n",
    "\n",
    "score_list =[]\n",
    "title_list =[]\n",
    "writer_list =[]\n",
    "date_list =[]\n",
    "content_list =[]\n",
    "sum_list =[]\n",
    "\n",
    "\n",
    "for line in data:\n",
    "    score_list.append(line[0])\n",
    "    title_list.append(line[1])\n",
    "    writer_list.append(line[2])\n",
    "    date_list.append(line[3])\n",
    "    content_list.append(line[4])\n",
    "    sum_list.append(line[5])\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "data_df = pd.DataFrame({\n",
    "    'score': score_list,\n",
    "    'title' : title_list,\n",
    "    'date' : date_list,\n",
    "    'content' : content_list,\n",
    "    'sum' : sum_list\n",
    "})\n",
    "\n",
    "data_df.to_csv('./data/service_imdb_wordcloud.csv', mode='w', encoding='utf-8')\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "back = pd.read_csv('./data/service_imdb_wordcloud.csv',encoding='utf-8')\n",
    "back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordcloud=WordCloud(\n",
    "    width=2400,height=1800,stopwords=set(STOPWORDS)).generate(sum_review)\n",
    "plt.imshow(wordcloud)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 자연어 처리 기초\n",
    "- 꼬꼬마\n",
    "- 한나눔\n",
    "- 트위터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from konlpy.tag import Kkma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkoma =Kkma()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkoma.nouns('한국어 문장 분석을 시작합니다. 재미있어요~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkoma.sentences('한국어 문장 분석을 시작합니다. 재미있어요~')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kkoma.pos('한국어 문장 분석을 시작합니다. 재미있어요~') # 단어들의 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 워드클라우드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud, STOPWORDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = open('C:/Users/A/data/07. alice.txt').read()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alice_mask = np.array(Image.open('C:/Users/A/images/07. alice_mask.png'))\n",
    "alice_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# 한글 폰트 문제 해결\n",
    "import platform\n",
    "\n",
    "from matplotlib import font_manager, rc\n",
    "# plt.rcParams['axes.unicode_minus'] = False\n",
    "\n",
    "if platform.system() == 'Darwin':\n",
    "    rc('font', family='AppleGothic')\n",
    "elif platform.system() == 'Windows':\n",
    "    path = \"c:/Windows/Fonts/malgun.ttf\"\n",
    "    font_name = font_manager.FontProperties(fname=path).get_name()\n",
    "    rc('font', family=font_name)\n",
    "else:\n",
    "    print('Unknown system... sorry~~~~') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 엘리스 그림 모양\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.imshow(alice_mask, cmap=plt.cm.gray)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sw = set(STOPWORDS)\n",
    "sw.add('said')\n",
    "wc = WordCloud(background_color='white', max_words=2000, mask=alice_mask, stopwords=sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wc = wc.generate(text)\n",
    "wc.words_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 엘리스 그림 모양\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.imshow(wc, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
